================================================================================
                         CAREERMATCH AI - PROJECT REPORT
                     DETAILED DATA MINING PROJECT DOCUMENTATION
================================================================================

Project: CareerMatch AI
Version: 2.1
University: IULM University - A.Y. 2025-2026
Course: Data Mining & Text Analytics
Professor: Prof. Alessandro Bruno
License: PolyForm Noncommercial License 1.0.0

================================================================================
                              1. GENERAL OVERVIEW
================================================================================

CareerMatch AI is an intelligent analytics platform that uses Machine Learning 
and NLP (Natural Language Processing) to analyze the compatibility between 
CVs and job postings.

MAIN OBJECTIVES:
- Calculate a match score between CV and Job Description
- Identify missing and transferable skills
- Provide a personalized learning path
- Suggest alternative roles based on candidate profile

LIVE DEMO URL: https://dataminingiulm.streamlit.app/
REPOSITORY: https://github.com/Giacomod2001/datamining

================================================================================
                           2. PROJECT STRUCTURE
================================================================================

datamining_git/
├── app.py              (106 KB, ~2250 lines) - Main Streamlit Application
├── ml_utils.py         (115 KB, ~2700 lines) - ML and Text Mining Algorithms
├── constants.py        (7 KB, ~120 lines)    - Knowledge Base (Skills, Rules)
├── styles.py           (30 KB, ~820 lines)   - CSS Design System
├── requirements.txt    (2 KB)                - Python Dependencies
├── README.md           (6 KB)                - Documentation
├── Acknowledgment      (1 KB)                - AI Tools Acknowledgments
├── LICENSE             (5 KB)                - PolyForm Noncommercial License 1.0.0
├── Demo_Candidate_DS_CV.pdf                  - Sample CV
├── PROJECT_REPORT.txt   (23 KB)              - This Documentation
├── .devcontainer/                            - Dev Container Configuration
├── .github/                                  - GitHub Actions/Workflows
└── .gitignore                                - Git Ignore File

================================================================================
                        3. APPLICATION ARCHITECTURE
================================================================================

The application follows a 3-tier architecture:

┌─────────────────────────────────────────────────────────────────────────────┐
│                           FRONTEND (app.py)                                  │
│   - Interactive Streamlit Dashboard                                          │
│   - Plotly Visualizations (gauge, scatter, bar charts)                      │
│   - Premium CSS with glassmorphism (styles.py)                              │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                          BACKEND (ml_utils.py)                               │
│   - Random Forest Classifier for skill matching                              │
│   - K-Means & Hierarchical Clustering                                        │
│   - LDA Topic Modeling                                                       │
│   - Named Entity Recognition (NER)                                           │
│   - Fuzzy Matching for skill extraction                                      │
└─────────────────────────────────────────────────────────────────────────────┘
                                    │
                                    ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                      KNOWLEDGE BASE (constants.py)                           │
│   - Hard Skills with synonyms and variants                                  │
│   - Soft Skills database                                                     │
│   - Inference Rules (skill → related skills)                                │
│   - Skill Clusters (tool equivalences)                                      │
│   - Job Archetypes for Career Compass                                       │
└─────────────────────────────────────────────────────────────────────────────┘

================================================================================
                    4. DATA MINING TECHNIQUES IMPLEMENTED
================================================================================

The project implements the following techniques from the Data Mining course:

------------------------------------------------------------------------------
4.1 KNOWLEDGE DISCOVERY PROCESS (KDD)
------------------------------------------------------------------------------

Step 1: DATA CLEANING
    - Text preprocessing: lowercase, noise removal
    - Tokenization with NLTK
    - Special character and encoding handling

Step 2: DATA INTEGRATION
    - Merge CV + Job Description + Portfolio
    - Information fusion from multiple sources (PDF, text)

Step 3: DATA SELECTION
    - Relevant section extraction
    - Multilingual stop words filtering (EN, IT, ES, FR, DE)

Step 4: DATA TRANSFORMATION
    - TF-IDF Vectorization (Term Frequency-Inverse Document Frequency)
    - N-gram generation (unigram, bigram, trigram)
    - Character n-grams for clustering

Step 5: DATA MINING
    - Classification (Random Forest)
    - Clustering (K-Means, Hierarchical)
    - Topic Modeling (LDA)

Step 6: PATTERN EVALUATION
    - Match score calculation
    - Confidence calculation
    - Transferable skill identification

Step 7: KNOWLEDGE PRESENTATION
    - Interactive dashboard
    - Plotly charts
    - Automatically generated PDF reports

------------------------------------------------------------------------------
4.2 MACHINE LEARNING ALGORITHMS
------------------------------------------------------------------------------

A) RANDOM FOREST CLASSIFIER
   Course Reference: "Classification and Regression", "Decision Tree"
   
   Parameters:
   - n_estimators: 150 trees
   - max_depth: 15 (overfitting prevention)
   - min_samples_split: 5
   - min_samples_leaf: 3
   - max_features: sqrt(features)
   - class_weight: balanced
   
   Usage: Classification of text fragments into skill categories.
   Pipeline: TF-IDF (3000 features, n-grams 1-3) → Random Forest

B) K-MEANS CLUSTERING
   Course Reference: "Clustering Techniques", "K-means"
   
   Parameters:
   - n_clusters: max(2, min(N/3, 5)) - heuristic
   - n_init: 20 initializations
   - max_iter: 500
   - algorithm: elkan (faster)
   
   Usage: Semantic grouping of skills for visualization.

C) HIERARCHICAL CLUSTERING (Agglomerative)
   Course Reference: "Hierarchical Clustering"
   
   Parameters:
   - Method: Ward linkage (minimizes intra-cluster variance)
   
   Output: Skill dendrogram to visualize hierarchical relationships.

D) LATENT DIRICHLET ALLOCATION (LDA)
   Course Reference: "Topic Model"
   
   Parameters:
   - n_components: 3-5 topics
   - max_iter: 50 (5x standard for convergence)
   - learning_method: batch (more accurate for small datasets)
   
   Usage: Latent topic extraction from Job Descriptions.

E) PRINCIPAL COMPONENT ANALYSIS (PCA)
   Course Reference: "Dimensionality Reduction"
   
   Parameters:
   - n_components: 2 (for 2D visualization)
   
   Usage: Dimensionality reduction for cluster scatter plots.


------------------------------------------------------------------------------
4.3 TEXT MINING TECHNIQUES
------------------------------------------------------------------------------

A) TF-IDF VECTORIZATION
   - Term Frequency: term frequency in document
   - Inverse Document Frequency: penalizes overly common terms
   - Formula: TF-IDF(t,d) = TF(t,d) × log(N/DF(t))
   - Sublinear TF: log(1 + tf)

B) N-GRAM ANALYSIS
   - Unigram: single words ("Python", "SQL")
   - Bigram: pairs ("machine learning", "data analysis")
   - Trigram: triples ("natural language processing")
   - Character n-grams: for skill clustering (2-4 characters)

C) FUZZY STRING MATCHING
   - Algorithm: Levenshtein Distance
   - Threshold: 85% similarity
   - Library: thefuzz (FuzzyWuzzy)
   - Usage: Typo tolerance ("Phyton" → "Python")

D) NAMED ENTITY RECOGNITION (NER)
   - Library: NLTK
   - Categories: ORGANIZATION, GPE (Location), PERSON
   - Post-processing: false positive filtering
   - Support: Italian names, European cities

================================================================================
                           5. DETAILED KNOWLEDGE BASE
================================================================================

------------------------------------------------------------------------------
5.1 HARD SKILLS (constants.py)
------------------------------------------------------------------------------

Main categories (skills focused on Data Mining course content):

• DATA MINING CONCEPTS
  Data Mining, Big Data, Business Intelligence, Knowledge Discovery

• KDD PROCESS
  Data Cleaning, Data Integration, Data Transformation, Pattern Evaluation

• DATABASES & STORAGE
  Database, Data Warehouse, Data Lake, SQL, OLAP

• ANALYSIS TECHNIQUES
  Clustering, K-Means, Hierarchical Clustering, Classification, 
  Decision Tree, Random Forest, Neural Network, Regression, 
  Association Analysis, Outlier Analysis

• DATA TYPES
  Structured Data, Unstructured Data, Semi-Structured Data, Time Series

• STATISTICS
  Statistics, Hypothesis Testing

------------------------------------------------------------------------------
5.2 SOFT SKILLS
------------------------------------------------------------------------------

• Analytical Thinking, Problem Solving, Decision Making, Communication

------------------------------------------------------------------------------
5.3 INFERENCE RULES
------------------------------------------------------------------------------

Hierarchical inference rules (skill → related skills):

Examples:
- KDD → Data Cleaning, Data Integration, Data Transformation, Pattern Evaluation
- Clustering → Unsupervised Learning, K-Means, Hierarchical Clustering
- Classification → Supervised Learning, Decision Tree, Random Forest
- Data Warehouse → OLAP, Data Integration, Historical Data

------------------------------------------------------------------------------
5.4 SKILL CLUSTERS (Equivalences)
------------------------------------------------------------------------------

Tools considered equivalent for matching:

• Supervised Learning: Classification, Regression, Decision Tree, Random Forest
• Unsupervised Learning: Clustering, K-Means, Hierarchical Clustering
• Data Storage: Database, Data Warehouse, Data Lake, DBMS
• Pattern Discovery: Association Analysis, Frequent Patterns, Market Basket

================================================================================
                        6. APPLICATION FEATURES
================================================================================

------------------------------------------------------------------------------
6.1 MAIN FEATURES
------------------------------------------------------------------------------

1. MATCH SCORE CALCULATION
   - CV-JD percentage compatibility score
   - Formula: (Matched + Transferable×0.5 + Project×0.3) / Required × 100
   - Interpretation: Excellent (≥80%), Good (≥60%), Moderate (≥40%)

2. TRANSFERABLE SKILLS RECOGNITION
   - Identifies equivalent skills using SKILL_CLUSTERS
   - e.g., "Power BI" in CV satisfies "Tableau" requirement
   - Contributes 50% to match score

3. GAP ANALYSIS
   - List of missing skills
   - Prioritization by importance

4. COVER LETTER ANALYSIS
   - Keyword coverage (hard skills)
   - Soft skills coverage
   - Structure score (greeting, closing, paragraphs)
   - Personalization score
   - Strengths & Improvements feedback

5. PROJECT EVALUATION (Portfolio)
   - Skill verification through projects
   - Portfolio Quality Score
   - Interview Talking Points
   - Project-based skill verification

6. CAREER COMPASS
   - Alternative role suggestions
   - Based on Job Archetypes
   - Match score for similar roles

7. LEARNING PATH
   - Course suggestions (Coursera, Udemy, YouTube)
   - Direct links for each missing skill
   - Resources organized by skill

8. EXPORT PDF
   - Professionally generated report
   - Includes skill matrix, learning roadmap
   - Direct download

9. CV BUILDER (NEW v2.1)
   - 4-step guided workflow: Profile, Skills, Experience, Export
   - Real-time JD optimization scoring
   - Sidebar with "Load Demo" and "Exit Demo" controls
   - PDF/TXT export with professional formatting
   - AI suggestions for missing skills

------------------------------------------------------------------------------
6.2 DEMO MODE
------------------------------------------------------------------------------

The application includes demo data for quick testing:
- Sample CV: Marco Bianchi (Marketing Data Analyst)
- Sample JD: Senior Marketing Analyst
- Demo Project: E-commerce Analytics Dashboard
- Demo Cover Letter

Optimized for ~93% match score (13/14 skills matched).

================================================================================
                          7. USER INTERFACE (UI/UX)
================================================================================

------------------------------------------------------------------------------
7.1 DESIGN SYSTEM (styles.py)
------------------------------------------------------------------------------

COLOR PALETTE (LinkedIn-inspired):
- Primary Blue: #0077B5
- Primary Dark: #004471
- Primary Light: #00A0DC
- Accent Green: #00C853 (matched skills)
- Accent Amber: #FFB300 (transferable)
- Accent Red: #E53935 (missing)
- Background: #0d1117 (dark theme)

EFFECTS:
- Glassmorphism on cards
- Smooth transitions (0.15s - 0.5s)
- Hover effects with scale and shadow
- Fade-in and shimmer animations

RESPONSIVE:
- Breakpoint: 768px
- Adaptive sidebar
- Dynamic multi-column layout

------------------------------------------------------------------------------
7.2 UI COMPONENTS
------------------------------------------------------------------------------

- Hero Section with statistics
- Input columns (2-4 dynamic)
- Colored skill tags (matched, missing, transferable, project, bonus)
- Gauge chart for match score
- Expanders for collapsible sections
- Developer Console (hidden debugger)

================================================================================
                           8. TECHNICAL DEPENDENCIES
================================================================================

requirements.txt:

# FRONTEND
streamlit>=1.41.0    - Dashboard framework
plotly               - Interactive charts

# DATA PROCESSING
pandas               - Data manipulation
numpy                - Numerical computing

# MACHINE LEARNING
scikit-learn         - RF, K-Means, TF-IDF, LDA, PCA
scipy                - Hierarchical Clustering

# TEXT MINING
nltk                 - NER, tokenization
thefuzz              - Fuzzy matching
python-levenshtein   - Levenshtein optimization
wordcloud            - Word cloud generation

# PDF
PyPDF2               - PDF text extraction
fpdf                 - PDF report generation

# UTILITIES
matplotlib           - Static charts (dendrograms)
graphviz             - Graph visualization
requests             - HTTP requests

================================================================================
                             9. DETAILED FILES
================================================================================

------------------------------------------------------------------------------
9.1 app.py (~2250 lines)
------------------------------------------------------------------------------

STRUCTURE:
1. Streamlit page configuration
2. Session state management
3. render_debug_page() - Developer Console with 6 tabs:
   - System: ML models overview
   - Analysis: Results breakdown
   - Clusters: Skill clustering visualization
   - NLP: Text analytics insights
   - Knowledge: Database browser
   - CV Builder State
4. render_home() - Main page:
   - Sidebar with controls
   - Hero section
   - Input columns
   - Analyze button
5. render_results() - Results visualization:
   - Match score gauge
   - Skills analysis tags
   - Cover letter analysis
   - Learning path
   - Career compass
   - Export PDF

------------------------------------------------------------------------------
9.2 ml_utils.py (~2700 lines)
------------------------------------------------------------------------------

MAIN FUNCTIONS:

train_rf_model()
    - Trains Random Forest with TF-IDF pipeline
    - Data augmentation for training

perform_skill_clustering(skills)
    - TF-IDF + K-Means + Hierarchical Clustering
    - PCA for 2D visualization
    - Output: DataFrame, dendrogram, cluster dict

perform_topic_modeling(corpus)
    - LDA with multilingual stop words
    - Word cloud generation
    - Topic interpretation

extract_entities_ner(text)
    - NLTK NER with post-processing
    - False positive filtering
    - Italian name support

extract_skills_from_text(text)
    - N-gram matching
    - Regex pattern matching
    - Fuzzy matching (85% threshold)
    - Inference rules application

analyze_gap(cv, jd)
    - Core matching algorithm
    - Calculates matched, missing, extra skills
    - Transferable skills via SKILL_CLUSTERS

analyze_gap_with_project(cv, jd, project)
    - Extends analyze_gap with portfolio verification
    - Portfolio quality score
    - Interview talking points

analyze_cover_letter(cl, jd, cv)
    - Keyword coverage analysis
    - Structure scoring
    - Personalization detection

generate_pdf_report(res)
    - Professional PDF generation
    - Skill matrix + learning roadmap

------------------------------------------------------------------------------
9.3 constants.py (~120 lines)
------------------------------------------------------------------------------

DATA STRUCTURES:

INFERENCE_RULES: Dict[str, List[str]]
    - Inference rules for skills
    - skill → [related skills]

HARD_SKILLS: Dict[str, List[str]]
    - Technical skills from Data Mining course
    - skill → [keywords, synonyms]

SOFT_SKILLS: Dict[str, List[str]]
    - Soft skill categories
    - skill → [keywords]

SKILL_CLUSTERS: Dict[str, Set[str]]
    - Equivalence clusters
    - category → {equivalent skills}

PROJECT_BASED_SKILLS: Set[str]
    - Skills requiring portfolio verification

================================================================================
                              10. TEAM & CREDITS
================================================================================

AUTHORS:
- Giacomo Dellacqua - Project Design (UI/UX & Application Architecture)
- Luca Tallarico - Machine Learning & NLP/Text Mining
- Ruben Scoletta - Testing, Quality Assurance & Documentation

AI TOOLS USED:
- Claude Opus 4 (thinking) - Primary AI assistant
- Gemini 3 Pro High - Debugging support
- Antigravity - Agentic development support

ACKNOWLEDGMENTS:
- Streamlit Team - Framework for rapid development
- Scikit-Learn - ML algorithms
- NLTK - Natural Language Processing

================================================================================
                             11. PROJECT METRICS
================================================================================

CODE STATISTICS:
- Total lines of code: ~6000+
- Python files: 4
- Configuration files: 5
- Knowledge base: Course-aligned skills

FUNCTIONAL COVERAGE:
- Stop words languages: 5 (EN, IT, ES, FR, DE)
- ML algorithms: 5 (RF, K-Means, Hierarchical, LDA, PCA)
- Text Mining techniques: 4 (TF-IDF, N-gram, Fuzzy, NER)

PERFORMANCE:
- Analysis time: ~5 seconds
- Match accuracy: ~85%

================================================================================
                                 12. CONCLUSIONS
================================================================================

CareerMatch AI represents a complete implementation of the KDD 
(Knowledge Discovery in Databases) process applied to the job matching domain.

The project demonstrates practical application of:
- Text Mining techniques for skill extraction
- Classification algorithms for categorization
- Clustering methods for semantic grouping
- Topic Modeling for thematic analysis
- Information Extraction with NER

The modular architecture and course-aligned knowledge base enable:
- Easy extension to new skill areas
- Customization of inference rules
- Integration of new algorithms

================================================================================
                    Report updated: January 11, 2026
                    CareerMatch AI v2.1 - IULM University
================================================================================
